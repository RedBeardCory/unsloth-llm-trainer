"""
This type stub file was generated by pyright.
"""

AutoModelForVision2Seq = ...
__all__ = ["FastBaseModel"]
NUM_LOGITS_TO_KEEP = ...
VLLM_SUPPORTED_VLM = ...
VLLM_NON_LORA_VLM = ...
PRE_COMPILE_INFERENCE = ...
PretrainedConfig = ...
HAS_TORCH_DTYPE = ...
_compile_config = ...
torch_compiler_set_stance = ...
def unsloth_base_fast_generate(self, *args, **kwargs):
    ...

class FastBaseModel:
    @staticmethod
    def from_pretrained(model_name=..., max_seq_length=..., dtype=..., load_in_4bit=..., load_in_8bit=..., load_in_16bit=..., full_finetuning=..., token=..., device_map=..., trust_remote_code=..., model_types=..., tokenizer_name=..., auto_model=..., use_gradient_checkpointing=..., supports_sdpa=..., whisper_language=..., whisper_task=..., auto_config=..., offload_embedding=..., float32_mixed_precision=..., fast_inference=..., gpu_memory_utilization=..., float8_kv_cache=..., random_state=..., max_lora_rank=..., disable_log_stats=..., unsloth_vllm_standby=..., **kwargs):
        ...
    
    @staticmethod
    def get_peft_model(model, r=..., target_modules=..., lora_alpha=..., lora_dropout=..., bias=..., finetune_vision_layers=..., finetune_language_layers=..., finetune_attention_modules=..., finetune_mlp_modules=..., layers_to_transform=..., layers_pattern=..., use_gradient_checkpointing=..., random_state=..., max_seq_length=..., use_rslora=..., modules_to_save=..., init_lora_weights=..., loftq_config=..., task_type=..., temporary_location=..., qat_scheme=..., **kwargs): # -> Any:
        ...
    
    @staticmethod
    def post_patch_model(model, use_gradient_checkpointing=..., trust_remote_code=..., model_type=..., tokenizer=..., float32_mixed_precision=...): # -> Any:
        ...
    
    @staticmethod
    def for_inference(model):
        ...
    
    @staticmethod
    def for_training(model, use_gradient_checkpointing=...):
        ...
    


